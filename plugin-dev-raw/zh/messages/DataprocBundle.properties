action.add.job.title=提交作業
action.cancel.job.confirm.msg=是否取消“{0}”作業?
action.cancel.job.title=取消作業
action.clone.job.title=克隆作業
action.cluster.remove.confirm.msg=是否刪除集群“{0}”?
action.cluster.start.confirm.msg=是否啟動集群“{0}”?
action.cluster.terminate.confirm.msg=是否終止集群“{0}”?
action.confirm.title=確認
action.delete.job.confirm.msg=是否刪除“{0}”作業?
action.delete.job.title=刪除作業
action.open.stage.bucket=開啟暫存存儲桶
action.sftp=開啟到節點的 SFTP
action.sftp.master.node=開啟到主節點的 SFTP
action.ssh=開啟到節點的 SSH
action.ssh.master.node=通過 SSH 連線到主節點
add.job.title=提交作業
add.new.submit.connection.label=新增 Dataproc 連線...
cell.execution.finished.msg=作業 "{0}" 已完成，狀態為 {1}。
cell.execution.finished.title=Dataproc 作業
cluster.action.delete=刪除集群
cluster.action.start=啟動集群
cluster.action.stop=終止集群
cluster.info.config.autoscaling=自動擴縮:
cluster.info.config.master.node.desc=主節點:
cluster.info.config.metastore=Dataproc 元存儲:
cluster.info.config.monitoring=完整性監控:
cluster.info.config.network=網絡:
cluster.info.config.region=區域:
cluster.info.config.scheduled.deletion=定時刪除:
cluster.info.config.secure.boot=安全啟動:
cluster.info.config.vtpm=VTPM:
cluster.info.config.worker.node.desc=工作程序節點:
cluster.info.config.zone=可用區
cluster.info.image.created=建立時間:
cluster.info.image.version=映像版本:
cluster.info.internal.ip=僅限內部 IP:
cluster.info.optional.components=可選組件:
cluster.info.summary.name=名稱:
cluster.info.summary.state=狀態:
cluster.info.summary.state.details=狀態詳細資訊:
cluster.info.summary.type=類型:
cluster.info.summary.uiid=集群 UUID:
cluster.tab.applications.title=應用程式
cluster.tab.info.title=資訊
cluster.tab.jobs.title=作業
cluster.tab.name=集群
cluster.tab.vb.instances.title=VM 實例
datamanager.configuration=組態
datamanager.job.info=作業資訊
datamanager.labels=標籤
datamanager.properties=屬性
datamanager.summary=匯總
dataproc.error=Dataproc 錯誤
dataproc.error.cluster.must.be.started=必須執行集群。
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=GC Dataproc 專案
emr.remove.linked.connections.title=Dataproc 連線
error.connection.is.not.found=未為 Dataproc 設定連線。請重新建立。
error.json.auth.limited.msg=僅當您使用 gcloud CLI 在 Dataproc 中進行身份驗證時，此動作才可用
error.json.auth.limited.title=動作不可用
group.name.dataproc=GC Dataproc
info.value.off=關閉
instance.config.gpu.number=GPU 數量
instance.config.local.ssd=本地 SSD
instance.config.machineType=機器類型:
instance.config.primary.disk.size=主磁碟大小:
instance.config.primary.disk.type=主磁碟類型:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=客戶端標記
job.info.cluster=集群:
job.info.continue.on.failure=失敗時繼續
job.info.elapsed.time=經過時間:
job.info.jobId=作業 ID:
job.info.jobUuid=作業 UUID:
job.info.max.restart.per.hour=每小時最大重啟:
job.info.max.restart.per.hour.hint=如果您不想在作業失敗時自動重啟，請留空。
job.info.open.job.files=在 GCS 中顯示作業目錄
job.info.properties=屬性
job.info.query.file=查詢:
job.info.query.file.value=查詢檔案:
job.info.query.text.value=查詢文本:
job.info.query.type=查詢源:
job.info.single.file.hint=可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案
job.info.spark.additional.py.files=附加 Python 檔案:
job.info.spark.additional.py.files.title=選擇附加 Py 檔案
job.info.spark.additional.r.files=附加 R 檔案:
job.info.spark.additional.r.files.title=選擇附加 R 檔案
job.info.spark.archives=歸檔:
job.info.spark.archives.hint=歸檔檔案已在 Spark 工作目錄中提取。可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案。支援的檔案類型包括: .jar、.tar、.tar.gz、.tgz、.zip。
job.info.spark.archives.title=選擇歸檔
job.info.spark.args=實參:
job.info.spark.files=檔案:
job.info.spark.jars=Jar:
job.info.spark.jars.hint=Jar 檔案包含在 CLASSPATH 中。可以是帶有 gs:// 前綴的 GCS 檔案、集群上帶有 hdfs:// 前綴的 HDFS 檔案或集群上帶有 file:// 前綴的本地檔案。
job.info.spark.jars.title=JAR
job.info.spark.main.class=主類別:
job.info.spark.main.py.file.title=選擇主 Py 檔案
job.info.spark.main.pyfile=主 Python 檔案:
job.info.spark.main.r.file=主 R 檔案:
job.info.spark.main.r.file.title=選擇主 R 檔案
job.info.start.date=開始日期:
job.info.status=狀態:
job.info.status.details=狀態詳細資訊:
job.info.type=作業類型:
job.label.block.title=標籤
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=屬性
job.pyspark.title=PySpark
job.query.file.dialog.title=選擇查詢檔案:
job.query.file.label=查詢檔案:
job.query.source.file=檔案
job.query.source.text=文本
job.query.source.type=查詢類型:
job.query.text.hint=要執行的查詢
job.query.text.label=查詢文本:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=有效
job.state.canceled=已取消
job.state.done=完成
job.state.failed=已失敗
job.validation.file.archive={0} 必須為歸檔類型 .jar、.tar、.tar.gz、.tgz、.zip。
job.validation.file.fs={0} 必須為帶有 gs://、hdfs:// 或 file:// 前綴的檔案
metainfo.cluster.id=ID:
metainfo.cluster.name=名稱:
metainfo.cluster.status=狀態:
remote.target.emr.cluster.remark=Dataproc 集群
resolve.artifact.is.not.supported=不支持檢測 {0} 的主類別。
settings.application.class.name.error.msg=請先選擇 jar 檔案
task.init.ssh.perform.cli.command=正在執行 GCloud CLI 指令…
task.init.ssh.title=Dataproc CLI 執行